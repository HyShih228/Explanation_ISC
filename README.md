# Explanation_ISC
We provide an explanation of how a large language model (LLM) responds to instructions, with a particular focus on its intrinsic self-correction behavior. In the experimental section, we use the Zephyr-7B-SFT model on the RealToxicityPrompts dataset, and this repository contains the code used to conduct our experiments.

## 
